{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Concatenate averaged raw & fil and vicarious calibration information into formatting for master datasheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Predefined wavelengths: weren't included in averaged files, may go back and do that later **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wavelengths_num = [412.0, 440.0, 488.0, 510.0, 532.0, 555.0, 650.0, 676.0, 715.0]\n",
    "wavelengths = [int(i) for i in wavelengths_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Import packages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from fopt_toolkit import fopt_toolkit as fp\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Filepaths for averaged raw/fil and vicarious calibration files **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vic_cal_filepath = fp.make_dir('Data/3_2_vic_averaged_summary_stats')\n",
    "averaged_filepath = fp.make_dir('Data/3_1_averaged_summary_stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Filepath to store summary data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_filepath = fp.make_dir('Data/4_overall_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Get the list of averaged fil/raw and vicarious calibration csv files from filepath **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vic_file_list = sorted(glob.glob(vic_cal_filepath+'/*.csv'))\n",
    "average_file_list = sorted(glob.glob(averaged_filepath+'/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_file_list = []\n",
    "fil_file_list = []\n",
    "for i in average_file_list:\n",
    "    if 'raw.csv' in i:\n",
    "        raw_file_list.append(i)\n",
    "    else:\n",
    "        fil_file_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Get dictionaries with dataframes (grouped by sample type) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fill_dict(file_list):\n",
    "    my_dictionary = {'a':[],'b':[],'c':[]}\n",
    "    for file_path in file_list:\n",
    "        file_name_cols = file_path.split('/')[-1].split('.')[0].split('_')\n",
    "        lake_name = file_name_cols[1]\n",
    "        sample_type = file_name_cols[2]\n",
    "        df = pd.read_csv(file_path, skiprows=0, delimiter= '\\t')\n",
    "        df['wl'] = wavelengths\n",
    "        df['lake'] = lake_name\n",
    "        my_dictionary[sample_type].append(df)\n",
    "    return my_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vic_cal_dfs = fill_dict(vic_file_list)\n",
    "raw_dfs = fill_dict(raw_file_list)\n",
    "fil_dfs = fill_dict(fil_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Concatenate and combine dataframes by sample type, rename columns **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_concat(my_dictionary):\n",
    "    all_data_frames = []\n",
    "    for sample_type in my_dictionary:\n",
    "        ## Get list of dataframes from my_dictionary\n",
    "        dfs = my_dictionary[sample_type]\n",
    "        ## Concatenate dfs (stacked)\n",
    "        concatenated_dfs = pd.concat(dfs)\n",
    "        ## Pivot dataframe so that each lake is its own row, columns are wavelengths\n",
    "        df_means = concatenated_dfs.pivot(index='lake',columns='wl',values='mean').rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        df_stds = concatenated_dfs.pivot(index='lake',columns='wl',values='std').rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        ## Get new names for columns\n",
    "        means_column_names = [sample_type+'_'+str(int(i))+'_mean' for i in list(df_means.columns)]\n",
    "        stds_column_names = [sample_type+'_'+str(int(i))+'_std' for i in list(df_stds.columns)]\n",
    "        ## Assign new column names to dataframes\n",
    "        df_means.columns = means_column_names\n",
    "        df_stds.columns = stds_column_names\n",
    "        ## Combine means and standard deviations\n",
    "        df_all = pd.concat([df_means,df_stds], axis = 1)\n",
    "        ## Sort columns\n",
    "        df_all = df_all.reindex_axis(sorted(df_all.columns), axis=1)\n",
    "        all_data_frames.append(df_all)\n",
    "    all_dfs_all_sample_types = pd.concat(all_data_frames, axis = 1)\n",
    "    all_dfs_all_sample_types = all_dfs_all_sample_types.reindex_axis(sorted(all_dfs_all_sample_types.columns), axis=1)\n",
    "    return all_dfs_all_sample_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-171b521fab50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvic_cal_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvic_cal_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfil_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-7f26bb6c2e72>\u001b[0m in \u001b[0;36mget_concat\u001b[0;34m(my_dictionary)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m## Concatenate dfs (stacked)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mconcatenated_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m## Pivot dataframe so that each lake is its own row, columns are wavelengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdf_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenated_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lake'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Petrichor/Library/Python/2.7/lib/python/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m   1452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Petrichor/Library/Python/2.7/lib/python/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "vic_cal_summary = get_concat(vic_cal_dfs)\n",
    "fil_summary = get_concat(fil_dfs)\n",
    "raw_summary = get_concat(raw_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Save to csv **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vic_cal_summary.to_csv(new_filepath+'/Vical_summary.csv', sep='\\t',index=True)\n",
    "fil_summary.to_csv(new_filepath+'/Fil_summary.csv', sep='\\t',index=True)\n",
    "raw_summary.to_csv(new_filepath+'/Raw_summary.csv', sep='\\t',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
