{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOVE AC9 Data Processing  \n",
    "\n",
    "## Averaging replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Catherine Kuhn, Elena TerziÄ‡ and Anna Simpson\n",
    "\n",
    "**Last Updated:** September 19th, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the required python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from scipy import interpolate\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.gridspec as gridspec\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in tools for this package (so far!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_id\n",
      "make_dir\n",
      "plotting_multiple_files\n"
     ]
    }
   ],
   "source": [
    "from fopt_toolkit import fopt_toolkit as fp\n",
    "for i in inspect.getmembers(fp, inspect.isfunction):\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_sample_filepath = fp.make_dir('Data/4_averaged_summary_stats')\n",
    "vic_cal_filepath = fp.make_dir('Data/4_vic_averaged_summary_stats_NO_BACKSCATTER_CORRECTION')\n",
    "averaged_figures_filepath = fp.make_dir('Figures/Averaged_reps')\n",
    "averaged_and_vic_figures_filepath = fp.make_dir('Figures/Vic_and_averaged_reps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload metadata file with filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_updated = pd.read_csv('../Metadata/project_metadata_updated.csv', dtype={'Date': object, 'Rep':object}, skiprows=0, delimiter= '\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average replicates - replicates from 'passed second removal' folder. CALIBRATION FILES NOT INCLUDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Makeing filepath_dict to store files for averaging. filepath_dict keys are combinations of site, analysis type (a or c), and sample_type (fil or raw, skipping cal); entries are dictionaries containing the replicate dataframes for those variables, separated into different dataframes for means and stds **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing dictionary\n",
    "\n",
    "Example entry: filepath_dict['9mi_a_raw'] = {'mean':[], 'std':[]}\n",
    "\n",
    "Then when filling, entries for 'mean' and 'std' will be a list of replicate dataframes for '9mi_a_raw', subset to just include the column mean or std with wl as the index. This way we can do different operations to combine the means and the stds, and then rebind the columns later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "### Subset the metadata to only use data that passed both removal steps\n",
    "### AND does not include calibration data\n",
    "temp = metadata_updated[metadata_updated['Pass_Second_Removal'] == 'pass'][metadata_updated['Sample_Type'] != 'cal']\n",
    "\n",
    "##Empty dictionary to store dataframes for averaging\n",
    "filepath_dict = {}\n",
    "## Iterate through all possible unique combinations of site, analysis type, and sample type\n",
    "for i in set(temp['Site']+'_'+temp['Analysis_Type']+'_'+temp['Sample_Type']):\n",
    "    ## Entries of dictionary are a dictionary with entries 'mean' and 'std\n",
    "    filepath_dict[i] = {'mean':[], 'std':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### iterate through the rows of the subsetted metadata\n",
    "for index, row in temp.iterrows():\n",
    "    ## Get information for each row to match the key value of filepath_dict\n",
    "    site = row['Site']\n",
    "    analysis_type = row['Analysis_Type']\n",
    "    sample_type = row['Sample_Type']\n",
    "    key_value = site+'_'+analysis_type+'_'+sample_type\n",
    "    ## Read in the csv based on the filepath\n",
    "    df = pd.read_csv(row['Summary_file_path_cleaned_MANUAL'], skiprows = 0, delimiter= '\\t')         \n",
    "    df.reset_index(inplace=True, drop=False)\n",
    "    ## Rename columns so we don't have to write multiple lines of code\n",
    "    df.rename(columns = {'c_mean':'mean', 'a_mean':'mean', 'c_std':'std','a_std':'std'}, inplace = True)\n",
    "    ## store means and stds separately for each set of reps to be averaged\n",
    "    ## Becaue they require different operations\n",
    "    ## (index values are wavelengths)\n",
    "    filepath_dict[key_value]['mean'].append(df[['wl','mean']].set_index('wl'))\n",
    "    filepath_dict[key_value]['std'].append(df[['wl','std']].set_index('wl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = list(df['wl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[412.0, 440.0, 488.0, 510.0, 532.0, 555.0, 650.0, 676.0, 715.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Custom aggregation function for combining standard deviations: for standard deviations x and y, combined std = sqrt(x^2 + y^2) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_std(series):\n",
    "    from math import sqrt\n",
    "    return sqrt(sum([i**2 for i in series]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_files = {i.split('_')[0]:{'a':{'fil':None,'raw':None},\\\n",
    "                                   #'b':{'fil':None,'raw':None},\\\n",
    "                                   'c':{'fil':None,'raw':None},\\\n",
    "                                   'va':{'vic':None},\\\n",
    "                                   #'vb':{'vic':None},\\\n",
    "                                   'vc':{'vic':None},\\\n",
    "                                  } for i in filepath_dict}\n",
    "for i in filepath_dict:\n",
    "    site = i.split('_')[0]\n",
    "    a_type = i.split('_')[1]\n",
    "    s_type = i.split('_')[2]\n",
    "    means = pd.concat(filepath_dict[i]['mean']).groupby(level=0).mean()\n",
    "    stds = pd.concat(filepath_dict[i]['std']).groupby(level=0).agg(combine_std)\n",
    "    #temp_series = temp_series.to_frame(name=i)\n",
    "    means['std'] = stds['std']\n",
    "    averaged_files[site][a_type][s_type] = means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scintillation/Documents/GitHub/FreshwatersOpticsToolkit/Data/4_averaged_summary_stats'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_sample_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scintillation/Documents/GitHub/FreshwatersOpticsToolkit/Data/4_vic_averaged_summary_stats_NO_BACKSCATTER_CORRECTION'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vic_cal_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in averaged_files:\n",
    "    ## define averaged files\n",
    "    absorption_raw = averaged_files[i]['a']['raw']\n",
    "    absorption_fil = averaged_files[i]['a']['fil']\n",
    "    attenuation_raw = averaged_files[i]['c']['raw']\n",
    "    attenuation_fil = averaged_files[i]['c']['fil']\n",
    "    ## Calculate means for backscatter\n",
    "    #raw_scatter_mean = attenuation_raw[['mean']]-absorption_raw[['mean']]\n",
    "    #fil_scatter_mean = attenuation_fil[['mean']]-absorption_fil[['mean']]\n",
    "    ## Calculate standard deviations for backscatter\n",
    "    #raw_scatter_std = pd.concat([absorption_raw[['std']], attenuation_raw[['std']]]).groupby(level=0).agg(combine_std)\n",
    "    #fil_scatter_std = pd.concat([absorption_fil[['std']], attenuation_fil[['std']]]).groupby(level=0).agg(combine_std)\n",
    "    ## Append standard deviations\n",
    "    #raw_scatter_mean['std'] = raw_scatter_std['std']\n",
    "    #fil_scatter_mean['std'] = fil_scatter_std['std']\n",
    "    ## Add backscatter dataframes to dictionary for plotting\n",
    "    #averaged_files[i]['b']['raw'] = raw_scatter_mean\n",
    "    #averaged_files[i]['b']['fil'] = fil_scatter_mean\n",
    "    ## Calculating vicarious calibration means\n",
    "    vic_absorption_mean = absorption_raw[['mean']]-absorption_fil[['mean']]\n",
    "    vic_attenuation_mean = attenuation_raw[['mean']] - attenuation_fil[['mean']]\n",
    "    #vic_scatter_mean = raw_scatter_mean[['mean']] - fil_scatter_mean[['mean']]\n",
    "    ## Calculating standard deviations for vicarious calibration\n",
    "    vic_absorption_std = pd.concat([absorption_raw[['std']], absorption_fil[['std']]]).groupby(level=0).agg(combine_std)\n",
    "    vic_attenuation_std = pd.concat([attenuation_raw[['std']], attenuation_fil[['std']]]).groupby(level=0).agg(combine_std)\n",
    "    #vic_scatter_std = pd.concat([raw_scatter_mean[['std']], fil_scatter_mean[['std']]]).groupby(level=0).agg(combine_std)\n",
    "    ## Putting new standard deviations into vicarious calibration dataframes\n",
    "    vic_absorption_mean['std'] = vic_absorption_std['std']\n",
    "    vic_attenuation_mean['std'] = vic_attenuation_std['std']\n",
    "    #vic_scatter_mean['std'] = vic_scatter_std['std']\n",
    "    ## Adding vicarious calibration dataframes to dictionary for plotting\n",
    "    averaged_files[i]['va']['vic'] = vic_absorption_mean\n",
    "    averaged_files[i]['vc']['vic'] = vic_attenuation_mean\n",
    "    #averaged_files[i]['vb']['vic'] = vic_scatter_mean\n",
    "    ### Save averaged files\n",
    "    absorption_raw.to_csv(averaged_sample_filepath+'/Averaged_'+i+'_'+'a_raw.csv', sep='\\t',index=False)\n",
    "    absorption_fil.to_csv(averaged_sample_filepath+'/Averaged_'+i+'_'+'a_fil.csv', sep='\\t',index=False)\n",
    "    attenuation_raw.to_csv(averaged_sample_filepath+'/Averaged_'+i+'_'+'c_raw.csv', sep='\\t',index=False)\n",
    "    attenuation_fil.to_csv(averaged_sample_filepath+'/Averaged_'+i+'_'+'c_fil.csv', sep='\\t',index=False)\n",
    "    #raw_scatter_mean.to_csv(averaged_sample_filepath+'/Averaged_'+i+'_'+'b_raw.csv', sep='\\t',index=False)\n",
    "    #fil_scatter_mean.to_csv(averaged_sample_filepath+'/Averaged_'+i+'_'+'b_fil.csv', sep='\\t',index=False)\n",
    "    ## Save vicariously calibrated files\n",
    "    vic_absorption_mean.to_csv(vic_cal_filepath+'/Vical_'+i+'_'+'a.csv', sep='\\t',index=False)\n",
    "    vic_attenuation_mean.to_csv(vic_cal_filepath+'/Vical_'+i+'_'+'c.csv', sep='\\t',index=False)\n",
    "    #vic_scatter_mean.to_csv(vic_cal_filepath+'/Vical_'+i+'_'+'b.csv', sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Plotting averaged absorption, backscatter, and attenuation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7c6bf903b2d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mabsorption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mattenuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'b'"
     ]
    }
   ],
   "source": [
    "for i in averaged_files:\n",
    "    absorption = averaged_files[i]['a']\n",
    "    attenuation = averaged_files[i]['c']\n",
    "    scatter = averaged_files[i]['b']\n",
    "    plt.subplots(1, 3, figsize=(14, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    fp.plotting_multiple_files(absorption, title='Absorption')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    fp.plotting_multiple_files(attenuation, title='Attenuation')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    fp.plotting_multiple_files(scatter, title='Backscatter')\n",
    "    plt.subplots_adjust(top=0.83, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.3)\n",
    "    plt.suptitle(i, fontsize=20)\n",
    "    plt.savefig(averaged_figures_filepath+'/Averaged_'+i+'.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7f6c33c251ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mabsorption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mattenuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvic_absorption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'va'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvic_attenuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maveraged_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'b'"
     ]
    }
   ],
   "source": [
    "for i in averaged_files:\n",
    "    absorption = averaged_files[i]['a']\n",
    "    attenuation = averaged_files[i]['c']\n",
    "    scatter = averaged_files[i]['b']\n",
    "    vic_absorption = averaged_files[i]['va']\n",
    "    vic_attenuation = averaged_files[i]['vc']\n",
    "    vic_scatter = averaged_files[i]['vb']\n",
    "    plt.subplots(2, 3, figsize=(14, 8))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    fp.plotting_multiple_files(absorption, title='Absorption')\n",
    "    plt.subplot(2, 3, 2)\n",
    "    fp.plotting_multiple_files(attenuation, title='Attenuation')\n",
    "    plt.subplot(2, 3, 3)\n",
    "    fp.plotting_multiple_files(scatter, title='Backscatter')\n",
    "    plt.subplot(2, 3, 4)\n",
    "    fp.plotting_multiple_files(vic_absorption, title='Vic. Calibrated Absorption')\n",
    "    plt.subplot(2, 3, 5)\n",
    "    fp.plotting_multiple_files(vic_attenuation, title='Vic. Calibrated Attenuation')\n",
    "    plt.subplot(2, 3, 6)\n",
    "    fp.plotting_multiple_files(vic_scatter, title='Vic. Calibrated Backscatter')\n",
    "    plt.subplots_adjust(top=0.88, bottom=0.02, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "    plt.suptitle(i, fontsize=20)\n",
    "    plt.savefig(averaged_and_vic_figures_filepath+'/Vicariosly_calibrated_'+i+'.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
