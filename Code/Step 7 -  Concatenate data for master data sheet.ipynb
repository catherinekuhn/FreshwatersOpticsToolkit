{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate averaged raw & fil and vicarious calibration information into formatting for master datasheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import packages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fopt_toolkit import fopt_toolkit as fp\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Filepaths for averaged raw/fil and vicarious calibration files **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_cal_filepath = fp.make_dir('Data/5_final_vical')\n",
    "averaged_filepath = fp.make_dir('Data/4_averaged_summary_stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Filepath to store summary data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filepath = fp.make_dir('Data/7_overall_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get the list of averaged fil/raw and vicarious calibration csv files from filepath **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_file_list = sorted(glob.glob(vic_cal_filepath+'/*.csv'))\n",
    "average_file_list = sorted(glob.glob(averaged_filepath+'/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_list = []\n",
    "fil_file_list = []\n",
    "for i in average_file_list:\n",
    "    if 'raw.csv' in i:\n",
    "        raw_file_list.append(i)\n",
    "    else:\n",
    "        fil_file_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get dictionaries with dataframes (grouped by sample type) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dict(file_list, scatter=True):\n",
    "    if scatter is True:\n",
    "        my_dictionary = {'a':[],'b':[],'c':[]}\n",
    "    else:\n",
    "        my_dictionary = {'a':[],'c':[]}\n",
    "    for file_path in file_list:\n",
    "        file_name_cols = file_path.split('/')[-1].split('.')[0].split('_')\n",
    "        lake_name = file_name_cols[1]\n",
    "        sample_type = file_name_cols[2]\n",
    "        df = pd.read_csv(file_path, skiprows=0, delimiter= '\\t')\n",
    "        df['lake'] = lake_name\n",
    "        my_dictionary[sample_type].append(df)\n",
    "    return my_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_cal_dfs = fill_dict(vic_file_list)\n",
    "raw_dfs = fill_dict(raw_file_list, scatter=False)\n",
    "fil_dfs = fill_dict(fil_file_list, scatter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Concatenate and combine dataframes by sample type, rename columns **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat(my_dictionary):\n",
    "    all_data_frames = []\n",
    "    for sample_type in my_dictionary:\n",
    "        ## Get list of dataframes from my_dictionary\n",
    "        dfs = my_dictionary[sample_type]\n",
    "        ## Concatenate dfs (stacked)\n",
    "        concatenated_dfs = pd.concat(dfs)\n",
    "        ## Pivot dataframe so that each lake is its own row, columns are wavelengths\n",
    "        df_means = concatenated_dfs.pivot(index='lake',columns='wl',values='mean').rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        df_stds = concatenated_dfs.pivot(index='lake',columns='wl',values='std').rename_axis(None, axis=0).rename_axis(None, axis=1)\n",
    "        ## Get new names for columns\n",
    "        means_column_names = [sample_type+'_'+str(int(i))+'_mean' for i in list(df_means.columns)]\n",
    "        stds_column_names = [sample_type+'_'+str(int(i))+'_std' for i in list(df_stds.columns)]\n",
    "        ## Assign new column names to dataframes\n",
    "        df_means.columns = means_column_names\n",
    "        df_stds.columns = stds_column_names\n",
    "        ## Combine means and standard deviations\n",
    "        df_all = pd.concat([df_means,df_stds], axis = 1)\n",
    "        ## Sort columns\n",
    "        df_all = df_all.reindex(sorted(df_all.columns), axis=1)\n",
    "        all_data_frames.append(df_all)\n",
    "    all_dfs_all_sample_types = pd.concat(all_data_frames, axis = 1)\n",
    "    all_dfs_all_sample_types = all_dfs_all_sample_types.reindex(sorted(all_dfs_all_sample_types.columns), axis=1)\n",
    "    return all_dfs_all_sample_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_cal_summary = get_concat(vic_cal_dfs)\n",
    "fil_summary = get_concat(fil_dfs)\n",
    "raw_summary = get_concat(raw_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Save to csv **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vic_cal_summary.to_csv(new_filepath+'/Vical_summary.csv', sep='\\t',index=True)\n",
    "fil_summary.to_csv(new_filepath+'/Fil_summary.csv', sep='\\t',index=True)\n",
    "raw_summary.to_csv(new_filepath+'/Raw_summary.csv', sep='\\t',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
