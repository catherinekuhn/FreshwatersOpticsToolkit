{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOVE | AC9 Data Processing\n",
    "***\n",
    "## 01 Read AC9 files\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Catherine Kuhn and Elena TerziÄ‡   \n",
    "**Last Updated:** August, 15th, 2018\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code reads in raw ac9 .dat files and parses sample information from the filename and header information inside the file. The output is a table of summary statistics formatted as a *.csv* file for each wavelength for each file. This code was built for a worflow in which a and c sides are sampled separately. File names should contain: date, site, rep, a or c side and water temperature. \n",
    "\n",
    "File names are formatted like ** AC9_dddddd_sit_sam_s_r_TXX_XX.dat** where:\n",
    "\n",
    "- **dddddd** = date (071718)\n",
    "- **sit** = three letter site code (fai)\n",
    "- **sam** = three letter sample type (cal, raw, fil) for calibration, raw water (unfiltered) or filtered (fil)\n",
    "- **r** = numbered replicate (1, 2, 3) \n",
    "- **TXX_X** = temperature in Celcius (T17_3)\n",
    "    \n",
    "**Ex:** AC9_071618_y17_raw_a_1_T17_6.dat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import the required python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ckuhn/Documents/ABOVE/Data/AC9/ac9_data/1_1_renamed_originals/cals\n"
     ]
    }
   ],
   "source": [
    "# Change to the desired directory\n",
    "%cd /Users/ckuhn/Documents/ABOVE/Data/AC9/ac9_data/1_1_renamed_originals/cals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all the files and sort them into a list\n",
    "AC9 = sorted(glob.glob('AC9*.dat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the columns in the upper part of the document for the wavelengths. Just to organize your main dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AC9_070718_lab_cal_a_1_T20_6.dat'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AC9[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skiprows_wavel = 9   # Skip the first 9 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ckuhn/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:53: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "for file in range(len(AC9)):\n",
    "\n",
    "    # brings in file\n",
    "    read_wl = pd.read_csv(AC9[file], skiprows=10, names=range(100), delimiter= '\\t')  # use names= range (100) to clip dangling columns\n",
    "    \n",
    "    # reads in a and c wavelength values from the first column of data\n",
    "    a_c_wl = read_wl[0][0:18]  ; a_wl = read_wl[0][0:9] ; c_wl = read_wl[0][9:18];\n",
    "    \n",
    "    # parses temperature, samplename, a or c side and site from the file name\n",
    "    # 0 = A, 0:3 takes AC9 (letters 0, 1, 2 not 3)\n",
    "    temperature = float(AC9[file][24:28].replace('_', '.'))\n",
    "    temp_string = AC9[file][24:28]; sample_type = AC9[file][15:18];  a_or_c = AC9[file][15:16];   \n",
    "    date = AC9[file][4:10];         site = AC9[file][11:14];   rep = AC9[file][21:22];\n",
    "\n",
    "    # make empty objects for your new variables of the wavelength value and name\n",
    "    # Example: wl_a: 650.0; wl_a_str: a650\n",
    "    wl_a = []    ; wl_c = []  ; wl_a_str = []  ; wl_c_str = []\n",
    "    \n",
    "    # makes a list of the 9 wavelengths formatted as floats\n",
    "    for i in range(len(a_wl)):\n",
    "        wl_a.append(np.float(a_wl[i][1:4]))\n",
    "        wl_a_str.append(a_wl[i])\n",
    "    for j in range(len(c_wl)):\n",
    "        wl_c.append(np.float(c_wl[j+9][1:4]))\n",
    "        wl_c_str.append(c_wl[j+9])\n",
    "    \n",
    "     # Unsorted list of wavelengths (412) and wavelength strings (a676)\n",
    "    wavelist = wl_a + wl_c                   ; wavelist_str = wl_a_str + wl_c_str   \n",
    "    # Unsorted list of wavelengths (412) and wavelength strings (a676) as arrays\n",
    "    wavelengths = np.asarray(wavelist)       ; wavelengths_str = np.asarray(wavelist_str)  \n",
    "    # Sorted list of a and c wavelengths as floats in an array (ex: 412, 440, etc)\n",
    "    wl_a_sorted = np.asarray(sorted(wl_a))   ; wl_c_sorted = np.asarray(sorted(wl_c))\n",
    "\n",
    "    # Now read back in the data, skipping all the header information  \n",
    "    # The time series of measured values starts in the 32th row\n",
    "    df1 = pd.read_csv(AC9[file], skiprows=31, delimiter= '\\t') \n",
    "    \n",
    "    # drops all the ragged extra columns dangling to the right\n",
    "    columns = df1.columns[19:len(df1.columns)]                 \n",
    "    df2 = df1.drop(columns, axis=1)    # you should have 19 cols left ~ array size [ntimesteps, 19]                       \n",
    "    \n",
    "    # drops the first column of the timestamp (ntimesteps)\n",
    "    columns1 = df2.columns[0]\n",
    "    df3 = df2.drop(columns1, axis=1)                    \n",
    "    \n",
    "    # makes a new header from the list of wavelengths you parsed earlier  \n",
    "    wl_header = wavelengths_str \n",
    "    \n",
    "    # Clean and reindex\n",
    "    df4 = df3[1:]                                       # take the data (row 1- n) less the header row (row 0)\n",
    "    df4.columns = wavelengths_str                       # set the header row as list of wavelengths\n",
    "    df4 = df4.reindex_axis(sorted(df4.columns), axis=1) # reindex them by the new sorted wavelengths\n",
    "    df4=df4.convert_objects(convert_numeric=True)       # Just to make sure that all elements are floats!\n",
    "    \n",
    "    no_cols = int(len(df4.columns)/2.)                  # no_col should always be 9 (one for each wavelength)         \n",
    "    \n",
    "    # Sort your dataframe with ascending walues of your wavelengths\n",
    "    # at this point the wl_a and wl_c are the same wavelengths so \n",
    "    # it doesn't matter which one you use here\n",
    "    new_header = wl_a_sorted\n",
    "    \n",
    "    # reindex to reshape the data\n",
    "    df_a_aux = df4.iloc[:, :no_cols];  df_a_aux.columns = new_header ;  df_a = df_a_aux.reindex_axis(sorted(df_a_aux.columns), axis = 1)\n",
    "    df_c_aux = df4.iloc[:, no_cols:];  df_c_aux.columns = new_header ;  df_c = df_c_aux.reindex_axis(sorted(df_c_aux.columns), axis = 1)\n",
    "    \n",
    "    # calculate the me(di)an, stdev, IQR for the time series - per each column\n",
    "    a_mean = df_a[wl_a_sorted].mean(axis=0)         ; c_mean = df_c[wl_c_sorted].mean(axis=0)   \n",
    "    a_std  = df_a[wl_a_sorted].std(axis=0)          ; c_std  = df_c[wl_c_sorted].std(axis=0)\n",
    "    a_median = df_a[wl_a_sorted].median(axis=0)     ; c_median = df_c[wl_c_sorted].median(axis=0)\n",
    "    \n",
    "    # Computing IQR\n",
    "    a_Q1 = df_a[wl_a_sorted].quantile(0.25)         ; c_Q1 = df_c[wl_c_sorted].quantile(0.25)\n",
    "    a_Q3 = df_a[wl_a_sorted].quantile(0.75)         ; c_Q3 = df_c[wl_c_sorted].quantile(0.75)\n",
    "    a_IQR = a_Q3 - a_Q1                             ; c_IQR = c_Q3 - c_Q1\n",
    "    \n",
    "    # Specifiy the output file name and directory\n",
    "    outputname = 'AC9_' + str(date) + '_'+ str(site) +'_' + str(sample_type) + '_' + str(a_or_c) +'_' + str(rep)+ '_'  + 'T' + str(temp_string) + '.csv'\n",
    "    outputdir = '/Users/ckuhn/Documents/ABOVE/Data/AC9/ac9_data/2_summarystats/cal/' + outputname \n",
    "    \n",
    "    # make a new dataframe from the summary statistics and export\n",
    "    if a_or_c == 'a':\n",
    "        output_df = pd.DataFrame([wl_a_sorted, a_mean, a_std, a_median, a_IQR]).swapaxes(0,1)\n",
    "        output_df.columns = ('wl', 'a_mean', 'a_std', 'a_median', 'a_IQR')\n",
    "        output_df.to_csv(outputdir, sep='\\t')\n",
    "    else:\n",
    "        output_df = pd.DataFrame([wl_c_sorted, c_mean, c_std, c_median, c_IQR]).swapaxes(0,1)\n",
    "        output_df.columns = ('wl', 'c_mean', 'c_std', 'c_median', 'c_IQR')\n",
    "        output_df.to_csv(outputdir, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
